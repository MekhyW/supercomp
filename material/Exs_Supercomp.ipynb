{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsAXY5K4dKRd",
        "outputId": "52a04603-9e33-4c56-9088-a74c9970aba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting file.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile file.cpp\n",
        "\n",
        "\n",
        "// monte carlo paralel\n",
        "// circle inside square\n",
        "// Cada thread irá gerar N/NUM_THREADS números aleatórios, atualizando sum com os pontos dentro do semi-círculo.\n",
        "\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <cmath>\n",
        "#include <omp.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // start the timer\n",
        "    double start = omp_get_wtime();\n",
        "    int n = 1000000;\n",
        "    int sum = 0;\n",
        "    double x, y;\n",
        "    // Each thread will generate N/NUM_THREADS random numbers, updating sum with the points inside the semi-circle.\n",
        "    #pragma omp parallel\n",
        "    {\n",
        "        random_device rd;\n",
        "        mt19937 gen(rd());\n",
        "        uniform_real_distribution<> dis(0, 1);\n",
        "        int local_sum = 0;\n",
        "        #pragma omp for\n",
        "        for (int i = 0; i < n; i++)\n",
        "        {\n",
        "            // print current thread number\n",
        "            // cout << \"Thread: \" << omp_get_thread_num() << endl;\n",
        "            x = dis(gen);\n",
        "            y = dis(gen);\n",
        "            if (sqrt(x * x + y * y) <= 1)\n",
        "            {\n",
        "                local_sum++;\n",
        "            }\n",
        "        }\n",
        "        #pragma omp atomic\n",
        "        sum += local_sum;\n",
        "    }\n",
        "    // end the timer\n",
        "    double end = omp_get_wtime();\n",
        "    cout << \"Time: \" << end - start << endl;\n",
        "    cout << \"Pi: \" << 4.0 * sum / n << endl;\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "/*The line of code you've highlighted is a directive for OpenMP,\n",
        "a library for parallel programming in C++. The #pragma omp atomic directive is used to\n",
        "ensure that a specific memory location is updated atomically to prevent race conditions.\n",
        "\n",
        "A race condition occurs when two or more threads can access shared data and they try to change it\n",
        "at the same time. As a result, the values of variables may be unpredictable and vary depending\n",
        "on the timings of context switches of the processes.\n",
        "\n",
        "The #pragma omp atomic directive ensures that a specific block of code is executed atomically.\n",
        "This means that the block of code is executed as a single, uninterruptible unit.\n",
        "It's a way to ensure that the operation (or sequence of operations)\n",
        "is completed by one thread before another thread has the\n",
        "chance to interrupt and perform the same operation.\n",
        "\n",
        "This directive is commonly used when performing increment, decrement, addition, and subtraction\n",
        "operations on shared variables in a multi-threaded environment.\n",
        "It's a simple and effective way to prevent race conditions and\n",
        "ensure the correct execution of your program when working with shared memory\n",
        "in a parallel computing context.*/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1myz-G-dXm-"
      },
      "outputs": [],
      "source": [
        "!g++ -g -Wall -fopenmp -o file file.cpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEsc8tNPdmJg",
        "outputId": "b0a55348-0aa8-4345-ae9f-a1377f665336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time: 0.105606\n",
            "Pi: 3.13884\n"
          ]
        }
      ],
      "source": [
        "!./file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY5dPrhs3zfx",
        "outputId": "76f62a9b-47cb-4348-8838-66480608e66e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing file2.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file file2.cpp\n",
        "\n",
        "#include<iostream>\n",
        "#include<omp.h>\n",
        "#include <unistd.h>\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "int main() {\n",
        "    long int i1, i2, imax = 1e9;\n",
        "    double sum1 = 0, sum2 = 0;\n",
        "\n",
        "    #pragma omp parallel sections num_threads(3)\n",
        "    {\n",
        "        #pragma omp section\n",
        "        {\n",
        "            for(i1 = 0; i1 < imax; i1++)\n",
        "                sum1 +=  i1;\n",
        "            cout << \"Task 1 - Done.\" << endl;\n",
        "        }\n",
        "\n",
        "        #pragma omp section\n",
        "        {\n",
        "            for(i2 = 0; i2 < imax; i2++)\n",
        "                sum2 -= i2;\n",
        "            cout << \"Task 2 - Done.\" << endl;\n",
        "\n",
        "        }\n",
        "\n",
        "        #pragma omp section\n",
        "        {\n",
        "            for(;i1<imax && i2<imax;){\n",
        "                sleep(1);\n",
        "                cout << \"Task 3 - i1 = \" << i1 << \" i2 = \" << i2 << endl;\n",
        "            }\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zA9urV531hC",
        "outputId": "83e462e6-ccfb-447a-e45c-56b4f77cb37c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task 3 - i1 = 86286590 i2 = 83991204\n",
            "Task 3 - i1 = 167442524 i2 = 167259672\n",
            "Task 3 - i1 = 255380593 i2 = 247936334\n",
            "Task 3 - i1 = 356946804 i2 = 364683798\n",
            "Task 3 - i1 = 482419582 i2 = 493566167\n",
            "Task 3 - i1 = 581967960 i2 = 610640562\n",
            "Task 3 - i1 = 667634240 i2 = 692687267\n",
            "Task 3 - i1 = 755950102 i2 = 775764815\n",
            "Task 3 - i1 = 841071299 i2 = 858213831\n",
            "Task 3 - i1 = 926680251 i2 = 937811584\n",
            "Task 2 - Done.\n",
            "Task 1 - Done.\n",
            "Task 3 - i1 = 1000000000 i2 = 1000000000\n"
          ]
        }
      ],
      "source": [
        "!g++ -g -Wall -fopenmp -o file2 file2.cpp\n",
        "!./file2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq9_2HTe7aK5",
        "outputId": "34d086c5-5bd5-419a-8d36-8075ae0bba92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting file3.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file file3.cpp\n",
        "\n",
        "// sequential leibniz pi\n",
        "#include <iostream>\n",
        "#include <omp.h>\n",
        "#include <cmath>\n",
        "#include <chrono>\n",
        "using namespace std;\n",
        "\n",
        "double sequentialLeibnizPi(int n) {\n",
        "    double sum = 0.0;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        sum += pow(-1, i) / (2 * i + 1);\n",
        "    }\n",
        "    return 4 * sum;\n",
        "}\n",
        "\n",
        "double parallelLeibnizPi(int n) {\n",
        "    double sum = 0.0;\n",
        "    #pragma omp parallel for reduction(+:sum)\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        sum += pow(-1, i) / (2 * i + 1);\n",
        "    }\n",
        "    return 4 * sum;\n",
        "}\n",
        "\n",
        "double TwoThreadsLeinbizPi(int n) {\n",
        "    double sum1 = 0.0;\n",
        "    double sum2 = 0.0;\n",
        "    #pragma omp parallel sections\n",
        "    {\n",
        "        #pragma omp section\n",
        "        {\n",
        "            for (int i = 0; i < n / 2; i++) {\n",
        "                sum1 += pow(-1, i) / (2 * i + 1);\n",
        "            }\n",
        "        }\n",
        "        #pragma omp section\n",
        "        {\n",
        "            for (int i = n / 2; i < n; i++) {\n",
        "                sum2 += pow(-1, i) / (2 * i + 1);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    return 4 * (sum1 + sum2);\n",
        "}\n",
        "\n",
        "double XThreadsLeibnizPi(int n, int numThreads) {\n",
        "    double sum = 0.0;\n",
        "    #pragma omp parallel for num_threads(numThreads) reduction(+:sum)\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        sum += pow(-1, i) / (2 * i + 1);\n",
        "    }\n",
        "    return 4 * sum;\n",
        "}\n",
        "\n",
        "double MasterThreadLeibnizPi(int n) {\n",
        "    double sum = 0.0;\n",
        "    #pragma omp parallel\n",
        "    {\n",
        "        #pragma omp master\n",
        "        {\n",
        "            cout << \"Number of threads: \" << omp_get_num_threads() << endl;\n",
        "        }\n",
        "        #pragma omp for reduction(+:sum)\n",
        "        for (int i = 0; i < n; i++) {\n",
        "            sum += pow(-1, i) / (2 * i + 1);\n",
        "        }\n",
        "    }\n",
        "    return 4 * sum;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1000000;\n",
        "    auto start = chrono::high_resolution_clock::now();\n",
        "    cout << \"Sequential: \" << sequentialLeibnizPi(n) << endl;\n",
        "    auto end = chrono::high_resolution_clock::now();\n",
        "    cout << \"Sequential time: \" << chrono::duration_cast<chrono::milliseconds>(end - start).count() << \"ms\" << endl;\n",
        "    start = chrono::high_resolution_clock::now();\n",
        "    cout << \"Parallel: \" << parallelLeibnizPi(n) << endl;\n",
        "    end = chrono::high_resolution_clock::now();\n",
        "    cout << \"Parallel time: \" << chrono::duration_cast<chrono::milliseconds>(end - start).count() << \"ms\" << endl;\n",
        "    start = chrono::high_resolution_clock::now();\n",
        "    cout << \"Two threads: \" << TwoThreadsLeinbizPi(n) << endl;\n",
        "    end = chrono::high_resolution_clock::now();\n",
        "    cout << \"Two threads time: \" << chrono::duration_cast<chrono::milliseconds>(end - start).count() << \"ms\" << endl;\n",
        "    start = chrono::high_resolution_clock::now();\n",
        "    cout << \"X threads: \" << XThreadsLeibnizPi(n, 12) << endl;\n",
        "    end = chrono::high_resolution_clock::now();\n",
        "    cout << \"X threads time: \" << chrono::duration_cast<chrono::milliseconds>(end - start).count() << \"ms\" << endl;\n",
        "    start = chrono::high_resolution_clock::now();\n",
        "    cout << \"Master thread: \" << MasterThreadLeibnizPi(n) << endl;\n",
        "    end = chrono::high_resolution_clock::now();\n",
        "    cout << \"Master thread time: \" << chrono::duration_cast<chrono::milliseconds>(end - start).count() << \"ms\" << endl;\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVjYbeC27deB",
        "outputId": "ff6d74da-4a08-4e93-b4d6-da639550bc49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential: 3.14159\n",
            "Sequential time: 21ms\n",
            "Parallel: 3.14159\n",
            "Parallel time: 18ms\n",
            "Two threads: 3.14159\n",
            "Two threads time: 21ms\n",
            "X threads: 3.14159\n",
            "X threads time: 18ms\n",
            "Master thread: Number of threads: 2\n",
            "3.14159\n",
            "Master thread time: 24ms\n"
          ]
        }
      ],
      "source": [
        "!g++ -g -Wall -fopenmp -o file3 file3.cpp\n",
        "!./file3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmCBROhi9Hka",
        "outputId": "7ba0d6a2-8dd5-46fe-e708-8fdb7bccb99f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting pi_rec.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file pi_rec.cpp\n",
        "\n",
        "#include <omp.h>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "static long num_steps = 1024*1024*1024;\n",
        "\n",
        "#define MIN_BLK  1024*1024*256\n",
        "\n",
        "double sum = 0;\n",
        "\n",
        "void pi_r(long Nstart, long Nfinish, double step) {\n",
        "    long i,iblk;\n",
        "    if (Nfinish-Nstart < MIN_BLK){\n",
        "        #pragma omp parallel for reduction(+:sum)\n",
        "        for (i = Nstart; i < Nfinish; i++){\n",
        "            double x = (i+0.5)*step;\n",
        "            sum += 4.0/(1.0+x*x);\n",
        "        }\n",
        "    } else {\n",
        "        iblk = Nfinish-Nstart;\n",
        "        #pragma omp task\n",
        "        pi_r(Nstart,         Nfinish-iblk/2,step);\n",
        "        #pragma omp task\n",
        "        pi_r(Nfinish-iblk/2, Nfinish,       step);\n",
        "        #pragma omp taskwait\n",
        "    }\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    double step, pi;\n",
        "    double init_time, final_time;\n",
        "    step = 1.0/(double) num_steps;\n",
        "    init_time = omp_get_wtime();\n",
        "    pi_r(0, num_steps, step);\n",
        "    pi = step * sum;\n",
        "    final_time = omp_get_wtime() - init_time;\n",
        "\n",
        "    std::cout << \"for \" << num_steps << \" steps pi = \" << std::setprecision(15) << pi << \" in \" << final_time << \" secs\\n\";\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQalM49h9KFR",
        "outputId": "f8c4c85d-328e-4582-9c08-46f5753d0194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1073741824 steps pi = 3.14159265358981 in 2.68497309599979 secs\n"
          ]
        }
      ],
      "source": [
        "!g++ -g -Wall -fopenmp -o pi_rec pi_rec.cpp\n",
        "!./pi_rec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wi9VbBhe7jY"
      },
      "source": [
        "Antes de usar a parte em cuda thrust lembre-se de mudar o ambiente de execução para a gpu (é só ir na setinha ao lado de ram e disco e selecionar alterar tipo de ambiente de execução)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtrO8GX7Zt0R",
        "outputId": "bfcc17d8-d426-4f22-89f7-a95745bdaaef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrgvpUMNZwdY",
        "outputId": "7a898e9e-b7a6-4127-9de0-6a8aeb0265a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting version.cu\n"
          ]
        }
      ],
      "source": [
        "%%file version.cu\n",
        "#include <thrust/version.h>\n",
        "#include <iostream>\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int major = THRUST_MAJOR_VERSION;\n",
        "  int minor = THRUST_MINOR_VERSION;\n",
        "\n",
        "  std::cout << \"Thrust v\" << major << \".\" << minor << std::endl;\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-YNcMSGZ9Ox",
        "outputId": "189ae14d-9e51-45d3-e0fe-e9862adf5579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thrust v2.2\n"
          ]
        }
      ],
      "source": [
        "!nvcc version.cu -o version\n",
        "!./version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JggYgPeJel_2",
        "outputId": "7051ac52-a5e3-48f9-eca4-24d95a347238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting thrust_example.cu\n"
          ]
        }
      ],
      "source": [
        "%%file thrust_example.cu\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/generate.h>\n",
        "#include <thrust/sort.h>\n",
        "#include <thrust/copy.h>\n",
        "#include <algorithm>\n",
        "#include <cstdlib>\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  // generate 32M random numbers serially\n",
        "  thrust::host_vector<int> h_vec(32 << 20);\n",
        "  std::generate(h_vec.begin(), h_vec.end(), rand);\n",
        "\n",
        "  // transfer data to the device\n",
        "  thrust::device_vector<int> d_vec = h_vec;\n",
        "\n",
        "  // sort data on the device\n",
        "  thrust::sort(d_vec.begin(), d_vec.end());\n",
        "\n",
        "  // transfer data back to host\n",
        "  thrust::copy(d_vec.begin(), d_vec.end(), h_vec.begin());\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaTlyQ-Desb8"
      },
      "outputs": [],
      "source": [
        "!nvcc thrust_example.cu -o thrust_example\n",
        "!./thrust_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH41wndQevDS",
        "outputId": "3fcb2205-63d4-4cf1-f883-a62397423515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==3080== NVPROF is profiling process 3080, command: ./thrust_example\n",
            "==3080== Profiling application: ./thrust_example\n",
            "==3080== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   39.59%  32.056ms         1  32.056ms  32.056ms  32.056ms  [CUDA memcpy HtoD]\n",
            "                   34.04%  27.562ms         1  27.562ms  27.562ms  27.562ms  [CUDA memcpy DtoH]\n",
            "                   13.97%  11.308ms         3  3.7695ms  3.7646ms  3.7788ms  void cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=1, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>(cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900 const *, cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=1, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>*, bool=1 const *, cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=1, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>**, bool=0*, cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=1, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>**, int, int, cub::CUB_200200_520_NS::GridEvenShare<cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=1, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>**>, int)\n",
            "                    7.38%  5.9769ms         2  2.9885ms  2.8749ms  3.1020ms  void cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=0, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>(cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900 const *, cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=0, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>*, bool=0 const *, cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=0, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>**, bool=0*, cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=0, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>**, int, int, cub::CUB_200200_520_NS::GridEvenShare<cub::CUB_200200_520_NS::DeviceRadixSortDownsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=0, bool=0, int, cub::CUB_200200_520_NS::NullType, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>**>, int)\n",
            "                    2.05%  1.6603ms         3  553.45us  525.65us  568.75us  void cub::CUB_200200_520_NS::DeviceRadixSortUpsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=1, bool=0, int, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>(cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900 const *, bool=1*, cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900 const *, int, int, cub::CUB_200200_520_NS::GridEvenShare<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900 const *>, bool=0)\n",
            "                    1.46%  1.1861ms         2  593.06us  590.23us  595.89us  void cub::CUB_200200_520_NS::DeviceRadixSortUpsweepKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, bool=0, bool=0, int, unsigned int, cub::CUB_200200_520_NS::detail::identity_decomposer_t>(cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900 const *, bool=0*, cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900 const *, int, int, cub::CUB_200200_520_NS::GridEvenShare<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900 const *>, bool=0)\n",
            "                    1.34%  1.0867ms         1  1.0867ms  1.0867ms  1.0867ms  [CUDA memcpy DtoD]\n",
            "                    0.17%  136.45us         5  27.289us  23.104us  33.568us  void cub::CUB_200200_520_NS::RadixSortScanBinsKernel<cub::CUB_200200_520_NS::DeviceRadixSortPolicy<int, cub::CUB_200200_520_NS::NullType, unsigned int>::Policy900, unsigned int>(cub::CUB_200200_520_NS::NullType*, int)\n",
            "      API calls:   67.48%  176.43ms         2  88.216ms  243.68us  176.19ms  cudaMalloc\n",
            "                   23.01%  60.166ms         3  20.055ms  18.609us  32.242ms  cudaMemcpyAsync\n",
            "                    8.16%  21.321ms         4  5.3302ms  2.8460us  21.232ms  cudaStreamSynchronize\n",
            "                    1.03%  2.6885ms         1  2.6885ms  2.6885ms  2.6885ms  cudaFuncGetAttributes\n",
            "                    0.19%  499.68us         2  249.84us  218.03us  281.66us  cudaFree\n",
            "                    0.05%  132.69us        15  8.8460us  4.0750us  31.782us  cudaLaunchKernel\n",
            "                    0.05%  130.17us       114  1.1410us     134ns  51.477us  cuDeviceGetAttribute\n",
            "                    0.01%  15.737us        12  1.3110us     411ns  6.4370us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags\n",
            "                    0.01%  15.318us        85     180ns     128ns     873ns  cudaGetLastError\n",
            "                    0.00%  11.947us         1  11.947us  11.947us  11.947us  cuDeviceGetName\n",
            "                    0.00%  8.2870us         1  8.2870us  8.2870us  8.2870us  cuDeviceGetPCIBusId\n",
            "                    0.00%  5.6430us        30     188ns     134ns     360ns  cudaPeekAtLastError\n",
            "                    0.00%  4.9960us         1  4.9960us  4.9960us  4.9960us  cuDeviceTotalMem\n",
            "                    0.00%  4.4530us         5     890ns     319ns  2.0030us  cudaGetDevice\n",
            "                    0.00%  2.0980us         2  1.0490us     703ns  1.3950us  cudaDeviceGetAttribute\n",
            "                    0.00%  1.5370us         3     512ns     233ns  1.0300us  cuDeviceGetCount\n",
            "                    0.00%  1.0830us         2     541ns     290ns     793ns  cuDeviceGet\n",
            "                    0.00%     457ns         1     457ns     457ns     457ns  cuModuleGetLoadingMode\n",
            "                    0.00%     237ns         1     237ns     237ns     237ns  cuDeviceGetUuid\n",
            "                    0.00%     195ns         1     195ns     195ns     195ns  cudaGetDeviceCount\n"
          ]
        }
      ],
      "source": [
        "!nvprof ./thrust_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytix4rkeeGbh",
        "outputId": "0abb732c-79ee-4dec-9797-dbc5ace82f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 23 12:41:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euxvsvwBewY4",
        "outputId": "d7be9863-3050-4cf9-c76d-e2d12486f0c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   2\n",
            "  On-line CPU(s) list:    0,1\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:           6\n",
            "    Model:                79\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   1\n",
            "    Socket(s):            1\n",
            "    Stepping:             0\n",
            "    BogoMIPS:             4399.99\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 cl\n",
            "                          flush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc re\n",
            "                          p_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3\n",
            "                           fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand\n",
            "                           hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp \n",
            "                          fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx sm\n",
            "                          ap xsaveopt arat md_clear arch_capabilities\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    32 KiB (1 instance)\n",
            "  L1i:                    32 KiB (1 instance)\n",
            "  L2:                     256 KiB (1 instance)\n",
            "  L3:                     55 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0,1\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Mitigation; PTE Inversion\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Vulnerable\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy barriers only; no swa\n",
            "                          pgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIBRS: Not affected; BH\n",
            "                          I: Vulnerable (Syscall hardening enabled)\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n"
          ]
        }
      ],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M54aUGiyhvv_",
        "outputId": "44ffedd3-64dc-4af6-e834-01567f9161a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing t_ex2.cu\n"
          ]
        }
      ],
      "source": [
        "%%file t_ex2.cu\n",
        "\n",
        "// This example demonstrates computing the sum of some random numbers in parallel:\n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/generate.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/random.h>\n",
        "\n",
        "int main() {\n",
        "  // Generate random data serially.\n",
        "  thrust::default_random_engine rng(1337);\n",
        "  thrust::uniform_real_distribution<double> dist(-50.0, 50.0);\n",
        "  thrust::host_vector<double> h_vec(32);\n",
        "  thrust::generate(h_vec.begin(), h_vec.end(), [&] { return dist(rng); });\n",
        "\n",
        "  // Transfer to device and compute the sum.\n",
        "  thrust::device_vector<double> d_vec = h_vec;\n",
        "  double x = thrust::reduce(d_vec.begin(), d_vec.end(), 0, thrust::plus<int>());\n",
        "\n",
        "  // Print the result.\n",
        "  std::cout << \"Sum: \" << x << std::endl;\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYtcHtaLh5qY",
        "outputId": "f8106ee3-cfff-4018-f1ec-6a337817171a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sum: -448\n"
          ]
        }
      ],
      "source": [
        "!nvcc t_ex2.cu -o t_ex2\n",
        "!./t_ex2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUVNCVyVh8i9",
        "outputId": "49336333-eedf-4743-f791-0d0d6d9092c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting t_ex3.cu\n"
          ]
        }
      ],
      "source": [
        "%%file t_ex3.cu\n",
        "\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/iterator/constant_iterator.h>\n",
        "#include <thrust/iterator/counting_iterator.h>\n",
        "#include <thrust/iterator/zip_iterator.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/scan.h>\n",
        "\n",
        "int main() {\n",
        "\n",
        "// alocate device vector\n",
        "thrust::device_vector<int> d_vec(4);\n",
        "\n",
        "thrust::device_vector<int>::iterator begin = d_vec.begin();\n",
        "thrust::device_vector<int>::iterator end = d_vec.end();\n",
        "\n",
        "int length = end - begin; // compute size of sequence\n",
        "\n",
        "end = d_vec.begin() + 3; // define a sequence of elemets\n",
        "\n",
        "// print the sequence\n",
        "for (int i = 0; i < length; i++) {\n",
        "  std::cout << d_vec[i] << \" \";\n",
        "}\n",
        "std::cout << std::endl;\n",
        "\n",
        " // print the end\n",
        "std::cout << *end << std::endl;\n",
        "\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5qUQOG2l_RX",
        "outputId": "27c40c78-c41f-4acd-9043-1fb3264fad99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb  t_ex2\t thrust_example\n",
            "file\t\t\t\t\t\t       t_ex2.cu  thrust_example.cu\n",
            "file.cpp\t\t\t\t\t       t_ex3\t version\n",
            "sample_data\t\t\t\t\t       t_ex3.cu  version.cu\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu6I04NxjEH3",
        "outputId": "6f0cafd2-3da3-408a-9f4f-a2c44cbea6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0 0 0 \n",
            "0\n"
          ]
        }
      ],
      "source": [
        "!nvcc t_ex3.cu -o t_ex3\n",
        "!./t_ex3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojRUomSwjFtm",
        "outputId": "76e14cac-2a66-42b7-973b-96839f8a1c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting t_ex4.cu\n"
          ]
        }
      ],
      "source": [
        "%%file t_ex4.cu\n",
        "\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/iterator/constant_iterator.h>\n",
        "#include <thrust/iterator/counting_iterator.h>\n",
        "#include <thrust/iterator/zip_iterator.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/scan.h>\n",
        "\n",
        "int main() {\n",
        "// thrust constant iterator\n",
        "thrust::constant_iterator<int> begin(10);\n",
        "thrust::constant_iterator<int> end = begin + 3;\n",
        "\n",
        "// begin[0] = 10, begin[1] = 10, begin[2] = 10\n",
        "// end[0] = 10, end[1] = 10, end[2] = 10\n",
        "\n",
        "int result;\n",
        "result = thrust::reduce(begin, end); // result = 30\n",
        "// print the result\n",
        "std::cout << \"Sum: \" << result << std::endl;\n",
        "return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDpJCAmkqX9m",
        "outputId": "6d2833ce-127d-4ac8-ee49-35c6396e27c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sum: 30\n"
          ]
        }
      ],
      "source": [
        "!nvcc t_ex4.cu -o t_ex4\n",
        "!./t_ex4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmyOYhGkqZcx",
        "outputId": "811f94c5-675a-47b0-a80c-4742c9070351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting t_ex5.cu\n"
          ]
        }
      ],
      "source": [
        "%%file t_ex5.cu\n",
        "\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/iterator/constant_iterator.h>\n",
        "#include <thrust/iterator/counting_iterator.h>\n",
        "#include <thrust/iterator/zip_iterator.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/scan.h>\n",
        "\n",
        "int main(){\n",
        "// thrust zip iterator\n",
        "thrust::device_vector<int> A(4);\n",
        "thrust::device_vector<char> B(4);\n",
        "\n",
        "A[0] = 1; A[1] = 2; A[2] = 3; A[3] = 4;\n",
        "B[0] = 'a'; B[1] = 'b'; B[2] = 'c'; B[3] = 'd';\n",
        "\n",
        "thrust::zip_iterator<thrust::tuple<thrust::device_vector<int>::iterator, thrust::device_vector<char>::iterator> > begin;\n",
        "thrust::zip_iterator<thrust::tuple<thrust::device_vector<int>::iterator, thrust::device_vector<char>::iterator> > end;\n",
        "\n",
        "begin = thrust::make_zip_iterator(thrust::make_tuple(A.begin(), B.begin()));\n",
        "end = thrust::make_zip_iterator(thrust::make_tuple(A.end(), B.end()));\n",
        "\n",
        "// begin[0] = (1,'a'), begin[1] = (2,'b'), begin[2] = (3,'c'), begin[3] = (4,'d')\n",
        "// end[0] = (1,'a'), end[1] = (2,'b'), end[2] = (3,'c'), end[3] = (4,'d')\n",
        "\n",
        "// maximum of [begin, end) with respect to the sum of the first elements\n",
        "thrust::maximum<thrust::tuple<int,char> > binary_op;\n",
        "thrust::reduce(begin, end, thrust::make_tuple(0,0), binary_op); // returns (4,'d')\n",
        "\n",
        "// declare the result\n",
        "thrust::tuple<int,char> result;\n",
        "result = thrust::reduce(begin, end, thrust::make_tuple(0,0), binary_op);\n",
        "\n",
        "// print the result\n",
        "std::cout << \"Result: \" << thrust::get<0>(result) << \" \" << thrust::get<1>(result) << std::endl;\n",
        "return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9FDNYl_rdWF",
        "outputId": "b7d7ae82-03b8-4228-b7f4-1270f28fde4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result: 4 d\n"
          ]
        }
      ],
      "source": [
        "!nvcc t_ex5.cu -o t_ex5\n",
        "!./t_ex5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMFO-40FreXz",
        "outputId": "4ac5ac53-949c-4434-b449-7f124f0994e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting integration.cu\n"
          ]
        }
      ],
      "source": [
        "%%file integration.cu\n",
        "\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/iterator/constant_iterator.h>\n",
        "#include <thrust/iterator/counting_iterator.h>\n",
        "#include <thrust/iterator/zip_iterator.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/scan.h>\n",
        "#include <thrust/sequence.h>\n",
        "#include <nvfunctional>\n",
        "#include <cstdlib>\n",
        "#include <algorithm>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "\n",
        "// define the square functor\n",
        "struct square\n",
        "{\n",
        "  __host__ __device__\n",
        "  float operator()(const float& x) const\n",
        "  {\n",
        "    return x * x;\n",
        "  }\n",
        "};\n",
        "\n",
        "int main() {\n",
        "  // declare the variables\n",
        "  thrust::device_vector<float> width(11, 0.1);\n",
        "  thrust::device_vector<float> height(11, 0.1);\n",
        "  thrust::device_vector<float> area(11, 0.1);\n",
        "  thrust::device_vector<float> accumulated_area(11, 0.1);\n",
        "  float total_area;\n",
        "\n",
        "  // declare the x-coordinate vector\n",
        "  thrust::device_vector<float> x(11);\n",
        "\n",
        "\n",
        "  thrust::sequence(x.begin(), x.end(), 0.0f, 0.1f);\n",
        "  std::cout << \"x: \";\n",
        "  for (int i = 0; i < x.size(); i++) {\n",
        "    std::cout << x[i] << \" \";\n",
        "  }\n",
        "  std::cout << std::endl;\n",
        "\n",
        "  // calculate the height of the trapezoids\n",
        "  thrust::transform(x.begin(), x.end(), height.begin(), square());\n",
        "\n",
        "  std::cout << \"Height: \";\n",
        "  for (int i = 0; i < height.size(); i++) {\n",
        "    std::cout << height[i] << \" \";\n",
        "  }\n",
        "  std::cout << std::endl;\n",
        "\n",
        "  // calculate the area of the trapezoids\n",
        "  thrust::transform(width.begin(), width.end(), height.begin(), area.begin(), thrust::multiplies<float>());\n",
        "\n",
        "  // print the area of the trapezoids\n",
        "    std::cout << \"Area: \";\n",
        "    for (int i = 0; i < area.size(); i++) {\n",
        "        std::cout << area[i] << \" \";\n",
        "        }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "  // calculate the total area under the curve\n",
        "  total_area = thrust::reduce(area.begin(), area.end());\n",
        "\n",
        "  // calculate the accumulated area under the curve at each x-coordinate\n",
        "  thrust::inclusive_scan(area.begin(), area.end(), accumulated_area.begin());\n",
        "\n",
        "  // print the results\n",
        "  std::cout << \"Total area: \" << total_area << std::endl;\n",
        "  std::cout << \"Accumulated area: \";\n",
        "  for (int i = 0; i < accumulated_area.size(); i++) {\n",
        "    std::cout << accumulated_area[i] << \" \";\n",
        "  }\n",
        "  std::cout << std::endl;\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLkeDwKOtDfe",
        "outputId": "777bb4d7-43ac-43b7-e743-63c7b36b7eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 \n",
            "Height: 0 0.01 0.04 0.09 0.16 0.25 0.36 0.49 0.64 0.81 1 \n",
            "Area: 0 0.001 0.004 0.009 0.016 0.025 0.036 0.049 0.064 0.081 0.1 \n",
            "Total area: 0.385\n",
            "Accumulated area: 0 0.001 0.005 0.014 0.03 0.055 0.091 0.14 0.204 0.285 0.385 \n"
          ]
        }
      ],
      "source": [
        "!nvcc integration.cu -o integration\n",
        "!./integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R_do1mstNmL",
        "outputId": "9ab82b48-b04c-453b-b8e1-7ca1d4a1d3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing teste_mpi.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file teste_mpi.cpp\n",
        "\n",
        "#include <unistd.h>\n",
        "#include <iostream>\n",
        "#include <mpi.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "    int rank, size;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    if (size != 2) {\n",
        "        cout << \"This program requires exactly 2 processes\" << endl;\n",
        "        MPI_Abort(MPI_COMM_WORLD, 1);\n",
        "    }\n",
        "\n",
        "    char hostname[256];\n",
        "    gethostname(hostname, sizeof(hostname));\n",
        "    int msg;\n",
        "\n",
        "    if (rank == 0){\n",
        "        msg = 42;\n",
        "        // send command format: MPI_Send(&data, count, datatype, destination, tag, communicator)\n",
        "        MPI_Send(&msg, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
        "        cout << \"Process\" << rank << \" sent message \" << msg << \" to process 1\" << endl;\n",
        "\n",
        "        MPI_Recv(&msg, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "        cout << \"Process\" << rank << \" received message \" << msg << \" from process 1\" << endl;\n",
        "\n",
        "    }\n",
        "    else {\n",
        "        MPI_Recv(&msg, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "        cout << \"Process \" << rank << \" received message \" << msg << \" from process 0\" << endl;\n",
        "\n",
        "        msg = 43;\n",
        "        MPI_Send(&msg, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n",
        "        cout << \"Process \" << rank << \" sent message \" << msg << \" to process 0\" << endl;\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brOqQ_AUxyhq"
      },
      "outputs": [],
      "source": [
        "!mpic++ teste_mpi.cpp -o teste_mpi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_AdmqLQxTeq",
        "outputId": "3021a8b9-577e-402d-f76e-7b605748c61c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process0 sent message 42 to process 1\n",
            "Process 1 received message 42 from process 0\n",
            "Process 1 sent message 43 to process 0\n",
            "Process0 received message 43 from process 1\n"
          ]
        }
      ],
      "source": [
        "!mpirun --allow-run-as-root --oversubscribe -n 2 ./teste_mpi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rua5o-270SOC",
        "outputId": "babe3d94-0d71-46c3-e101-cc3f284893b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing scatter_test.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file scatter_test.cpp\n",
        "\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "float compute_avg(float *arr, int size) {\n",
        "    float sum = 0.0;\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        sum += arr[i];\n",
        "    }\n",
        "    return sum / size;\n",
        "}\n",
        "\n",
        "float *create_rand_nums(int num_elements) {\n",
        "    float *rand_nums = new float [num_elements];\n",
        "    for (int i = 0; i < num_elements; i++) {\n",
        "        rand_nums[i] = (rand() / (float)RAND_MAX);\n",
        "    }\n",
        "    return rand_nums;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(NULL, NULL);\n",
        "\n",
        "    int world_rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
        "    int world_size;\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
        "\n",
        "    int elements_per_proc = 100; // Example number of elements per process\n",
        "    float *rand_nums = NULL; // Random numbers on root\n",
        "    float *sub_rand_nums = new float [elements_per_proc]; // Buffer for each process\n",
        "\n",
        "    if (world_rank == 0) {\n",
        "        rand_nums = create_rand_nums(elements_per_proc * world_size); // Assuming create_rand_nums is defined elsewhere\n",
        "    }\n",
        "\n",
        "    // Scatter the random numbers to all processes\n",
        "    MPI_Scatter(rand_nums, elements_per_proc, MPI_FLOAT, sub_rand_nums,\n",
        "                elements_per_proc, MPI_FLOAT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "    // Compute the average of your subset\n",
        "    float sub_avg = compute_avg(sub_rand_nums, elements_per_proc);\n",
        "\n",
        "    // Gather all partial averages down to the root process\n",
        "    float *sub_avgs = NULL;\n",
        "    if (world_rank == 0) {\n",
        "        sub_avgs = new float [world_size];\n",
        "    }\n",
        "\n",
        "    // Gather all partial averages down to the root process\n",
        "    MPI_Gather(&sub_avg, 1, MPI_FLOAT, sub_avgs, 1, MPI_FLOAT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "    if (world_rank == 0) {\n",
        "        float avg = compute_avg(sub_avgs, world_size);\n",
        "        printf(\"Global average: %f\\n\", avg);\n",
        "    }\n",
        "\n",
        "    delete(sub_rand_nums);\n",
        "    if (world_rank == 0) {\n",
        "        delete(rand_nums);\n",
        "        delete(sub_avgs);\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3e_acTA0VXS"
      },
      "outputs": [],
      "source": [
        "!mpic++ scatter_test.cpp -o scatter_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUY5qk7P0XFi",
        "outputId": "48f81cc2-d728-4669-a45f-b58ee21d4378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Global average: 0.506206\n"
          ]
        }
      ],
      "source": [
        "!mpirun --allow-run-as-root --oversubscribe -n 5 ./scatter_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fE-73kS0ZnK",
        "outputId": "ed6956b6-41e0-410d-b639-a00fd1b79563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpi_omp.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file mpi_omp.cpp\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "#include <omp.h>\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    int numprocs, rank, namelen;\n",
        "    char processor_name[20];\n",
        "    int iam = 0, np = 1;\n",
        "\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Get_processor_name(processor_name, &namelen);\n",
        "\n",
        "    #pragma omp parallel default(shared) private(iam)\n",
        "    {\n",
        "        np = omp_get_num_threads();\n",
        "        iam = omp_get_thread_num();\n",
        "        printf(\"Hybrid: Hello from thread %d out of %d from process %d out of %d on %s\\n\",\n",
        "                iam, np, rank, numprocs, processor_name);\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eIckpoyGOP4",
        "outputId": "2d432534-e7fb-4d2e-aed3-f3e550ff2fdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hybrid: Hello from thread 1 out of 2 from process 1 out of 2 on 76a253b8e3ea\n",
            "Hybrid: Hello from thread 0 out of 2 from process 1 out of 2 on 76a253b8e3ea\n",
            "Hybrid: Hello from thread 1 out of 2 from process 0 out of 2 on 76a253b8e3ea\n",
            "Hybrid: Hello from thread 0 out of 2 from process 0 out of 2 on 76a253b8e3ea\n"
          ]
        }
      ],
      "source": [
        "!mpic++ -fopenmp mpi_omp.cpp -o mpi_omp\n",
        "!mpirun --allow-run-as-root --oversubscribe -n 2 ./mpi_omp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8uPmF9ZGZbP",
        "outputId": "2247ca46-a8a9-4d8d-f15e-318d5887ace4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing quadrado.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file quadrado.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <mpi.h>\n",
        "#include <omp.h>\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "\tMPI_Init(&argc, &argv);\n",
        "\n",
        "\tint rank, size;\n",
        "\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "\tconst int N=10;\n",
        "\tint data[N][N];\n",
        "\n",
        "\n",
        "\t// Inicialização do array pelo processo 0\n",
        "\tif (rank == 0) {\n",
        "\t\tfor(int i=0; i<N; i++) {\n",
        "\t\t\tfor(int j=0; j<N; j++) {\n",
        "\t\t\t\tdata[i][j] = i+j;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\n",
        "        for(int i=0; i<N; i++) {\n",
        "\t\t\tfor(int j=0; j<N; j++) {\n",
        "\t\t\t\tstd::cout << data[i][j] << \" \";\n",
        "\t\t\t}\n",
        "\t\t\tstd::cout << std::endl;\n",
        "\t\t}\n",
        "        std::cout << std::endl << std::endl;\n",
        "\t}\n",
        "\n",
        "\t// Dividir o array entre os processos\n",
        "\tint chunk_size = N / size;\n",
        "\tint local_data[chunk_size][N];\n",
        "\tMPI_Scatter(&data, chunk_size*N, MPI_INT, &local_data, chunk_size*N, MPI_INT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "\t// Paralelização com OpenMP\n",
        "\t#pragma omp parallel for collapse(2)\n",
        "\tfor(int i=0; i<chunk_size; i++) {\n",
        "\t\tfor(int j=0; j<N; j++) {\n",
        "\t\t\tlocal_data[i][j] *= local_data[i][j];\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t// Reunir os resultados no processo 0\n",
        "\tMPI_Gather(&local_data, chunk_size*N, MPI_INT, &data, chunk_size*N, MPI_INT, 0, MPI_COMM_WORLD);\n",
        "\n",
        "\t// Processo 0 imprime os resultados\n",
        "\tif (rank == 0) {\n",
        "\t\tfor(int i=0; i<N; i++) {\n",
        "\t\t\tfor(int j=0; j<N; j++) {\n",
        "\t\t\t\tstd::cout << data[i][j] << \" \";\n",
        "\t\t\t}\n",
        "\t\t\tstd::cout << std::endl;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tMPI_Finalize();\n",
        "\treturn 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJqDvt3-H_b0",
        "outputId": "826b51a7-036e-4477-b3a5-006446ba7e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 5 6 7 8 9 \n",
            "1 2 3 4 5 6 7 8 9 10 \n",
            "2 3 4 5 6 7 8 9 10 11 \n",
            "3 4 5 6 7 8 9 10 11 12 \n",
            "4 5 6 7 8 9 10 11 12 13 \n",
            "5 6 7 8 9 10 11 12 13 14 \n",
            "6 7 8 9 10 11 12 13 14 15 \n",
            "7 8 9 10 11 12 13 14 15 16 \n",
            "8 9 10 11 12 13 14 15 16 17 \n",
            "9 10 11 12 13 14 15 16 17 18 \n",
            "\n",
            "\n",
            "0 1 4 9 16 25 36 49 64 81 \n",
            "1 4 9 16 25 36 49 64 81 100 \n",
            "4 9 16 25 36 49 64 81 100 121 \n",
            "9 16 25 36 49 64 81 100 121 144 \n",
            "16 25 36 49 64 81 100 121 144 169 \n",
            "25 36 49 64 81 100 121 144 169 196 \n",
            "36 49 64 81 100 121 144 169 196 225 \n",
            "49 64 81 100 121 144 169 196 225 256 \n",
            "8 9 10 11 12 13 14 15 16 17 \n",
            "9 10 11 12 13 14 15 16 17 18 \n"
          ]
        }
      ],
      "source": [
        "!mpic++ -fopenmp quadrado.cpp -o quadrado\n",
        "!mpirun --allow-run-as-root --oversubscribe -n 4 ./quadrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsjPhOXHIEVk",
        "outputId": "79e1d247-8efb-4032-9ccd-3784d97ddd7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing media.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file media.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <mpi.h>\n",
        "#include <omp.h>\n",
        "#include <chrono>\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    MPI_Init(&argc, &argv);\n",
        "    int rank, size;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    const int N = 1000000000; // Total de numeros\n",
        "    const int local_N = N / size; // Elementos por processo (máquina)\n",
        "\n",
        "    // Aloca memória para o vetor local\n",
        "    std::vector<double> local_data(local_N);\n",
        "\n",
        "    // Inicializa o vetor local. Para simplificar, usaremos o índice.\n",
        "    for (int i = 0; i < local_N; i++) {\n",
        "        local_data[i] = i + rank * local_N;\n",
        "    }\n",
        "\n",
        "    double local_sum = 0.0;\n",
        "\n",
        "    // Usa OpenMP para calcular a soma local\n",
        "    #pragma omp parallel for reduction(+:local_sum)\n",
        "    for (int i = 0; i < local_N; i++) {\n",
        "        local_sum += local_data[i];\n",
        "    }\n",
        "\n",
        "    // Reúne todas as somas locais para calcular a soma global\n",
        "    double global_sum = 0.0;\n",
        "    MPI_Reduce(&local_sum, &global_sum, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);\n",
        "\n",
        "    // Calcula a média no processo principal\n",
        "    if (rank == 0) {\n",
        "        double average = global_sum / N;\n",
        "        std::cout << \"The average is \" << average << std::endl;\n",
        "\n",
        "        auto end = std::chrono::high_resolution_clock::now();\n",
        "        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);\n",
        "        std::cout << \"Time taken: \" << duration.count() << \" milliseconds\" << std::endl;\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVrDs2DZIRLv",
        "outputId": "c5bc98ee-c87f-4e32-dfa1-1f70d133f3c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average is 5e+08\n",
            "Time taken: 11986 milliseconds\n"
          ]
        }
      ],
      "source": [
        "!mpic++ -fopenmp media.cpp -o media\n",
        "!mpirun --allow-run-as-root --oversubscribe -n 4 ./media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dwnoB9cIdLZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
